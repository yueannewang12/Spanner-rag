{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yueannewang12/Spanner-rag/blob/main/graph_rag_agent_engine_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26b655f",
      "metadata": {
        "id": "a26b655f"
      },
      "source": [
        "# Graph RAG + Vertex AI Agent Engine Deployment Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4debbfa",
      "metadata": {
        "id": "c4debbfa"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install --quiet google-cloud-aiplatform[adk,agent_engines]==1.121.0\n",
        "%pip install --quiet google-cloud-spanner==3.56.0\n",
        "%pip install --quiet langchain-google-spanner==0.8.2\n",
        "%pip install --quiet langchain-google-vertexai==2.0.22\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fddc8d93",
      "metadata": {
        "id": "fddc8d93"
      },
      "outputs": [],
      "source": [
        "from google.adk import Agent\n",
        "from google.adk.tools import agent_tool, google_search\n",
        "from google.adk.tools.function_tool import FunctionTool\n",
        "\n",
        "from vertexai import agent_engines\n",
        "import vertexai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "088b7ad8",
      "metadata": {
        "id": "088b7ad8"
      },
      "outputs": [],
      "source": [
        "from langchain_google_spanner import SpannerGraphVectorContextRetriever\n",
        "\n",
        "def use_node_vector_retriever2(\n",
        "    question: str,\n",
        "    graph_store,\n",
        "    embedding_service,\n",
        "    label_expr=\"Product\",\n",
        "    expand_by_hops=1,\n",
        "):\n",
        "    retriever = SpannerGraphVectorContextRetriever.from_params(\n",
        "        graph_store=graph_store,\n",
        "        embedding_service=embedding_service,\n",
        "        label_expr=label_expr,\n",
        "        expand_by_hops=expand_by_hops,\n",
        "        top_k=1,\n",
        "        k=10,\n",
        "    )\n",
        "    return retriever.invoke(question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52599abc",
      "metadata": {
        "id": "52599abc"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "SPANNERGRAPH_QA_TEMPLATE = \"\"\"\n",
        "You are a helpful retail assistant.\n",
        "ONLY use the context; do not add knowledge.\n",
        "\n",
        "Information:\n",
        "Question: {question}\n",
        "Graph Schema: {graph_schema}\n",
        "Context: {context}\n",
        "\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=SPANNERGRAPH_QA_TEMPLATE,\n",
        "    input_variables=[\"question\", \"graph_schema\", \"context\"],\n",
        ")\n",
        "\n",
        "llm = ChatVertexAI(model=\"gemini-2.0-flash\", temperature=0)\n",
        "qa_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "def ask_graph(query: str):\n",
        "    from langchain_google_spanner import SpannerGraphStore\n",
        "\n",
        "    INSTANCE = \"properties\"\n",
        "    DATABASE = \"graph-rag-colab\"\n",
        "    GRAPH = \"my_graph\"\n",
        "\n",
        "    graph_store = SpannerGraphStore(\n",
        "        instance_id=INSTANCE,\n",
        "        database_id=DATABASE,\n",
        "        graph_name=GRAPH,\n",
        "    )\n",
        "\n",
        "    embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "\n",
        "    context = use_node_vector_retriever2(\n",
        "        question=query,\n",
        "        graph_store=graph_store,\n",
        "        embedding_service=embeddings,\n",
        "        label_expr=\"Product\",\n",
        "        expand_by_hops=1,\n",
        "    )\n",
        "\n",
        "    answer = qa_chain.invoke(\n",
        "        {\n",
        "            \"question\": query,\n",
        "            \"graph_schema\": graph_store.get_schema,\n",
        "            \"context\": context,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return {\"result\": answer}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9169e20",
      "metadata": {
        "id": "e9169e20"
      },
      "outputs": [],
      "source": [
        "def ask_graph_tool_function(query: str):\n",
        "    return ask_graph(query)\n",
        "\n",
        "ask_graph_tool = FunctionTool(ask_graph_tool_function)\n",
        "â‰ˆz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc49b45",
      "metadata": {
        "id": "3bc49b45"
      },
      "outputs": [],
      "source": [
        "\n",
        "search_agent = Agent(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    name=\"search_agent\",\n",
        "    instruction=\"External lookup expert.\",\n",
        "    tools=[google_search],\n",
        ")\n",
        "\n",
        "root_agent = Agent(\n",
        "    name=\"graph_rag_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=\"\"\"\n",
        "You are a retail assistant using a Google Spanner product graph.\n",
        "Always use ask_graph first.\n",
        "\"\"\",\n",
        "    tools=[\n",
        "        agent_tool.AgentTool(agent=search_agent),\n",
        "        ask_graph_tool,\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301fd398",
      "metadata": {
        "id": "301fd398"
      },
      "outputs": [],
      "source": [
        "app = agent_engines.AdkApp(\n",
        "    app_name=\"graph_rag_agent_app\",\n",
        "    agent=root_agent,\n",
        "    enable_tracing=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db73d8eb",
      "metadata": {
        "id": "db73d8eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "GCP_PROJECT_ID = \"anne-test-project1\"   # <-- your actual project ID\n",
        "REGION = \"us-central1\"                  # <-- your region\n",
        "\n",
        "GCP_PROJECT_NUMBER = \"198925083406\"\n",
        "\n",
        "STAGING_BUCKET = f\"gs://{GCP_PROJECT_ID}-vertexai-staging\"\n",
        "\n",
        "vertexai.init(\n",
        "    project=GCP_PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "remote_app = agent_engines.create(\n",
        "    display_name=\"graph_rag_agent_app\",\n",
        "    agent_engine=app,\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[adk]>=1.126.1\",\n",
        "        \"google-cloud-spanner==3.56.0\",\n",
        "        \"langchain-google-spanner==0.8.2\",\n",
        "        \"langchain-google-vertexai==2.0.22\",\n",
        "        \"langchain-experimental==0.3.4\",\n",
        "        \"pydantic==2.12.5\",\n",
        "        \"cloudpickle==3.1.1\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Resource Name:\", remote_app.resource_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Push the code to Colab"
      ],
      "metadata": {
        "id": "15cAEpxM2NBE"
      },
      "id": "15cAEpxM2NBE"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}